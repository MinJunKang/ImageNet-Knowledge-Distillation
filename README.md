# ImageNet-Knowledge-Distillation
Knowledge Distillation code with ImageNet dataset

# Teacher model
Resnet 18 (you can change with 50 or others)

# Data
ImageNet Dataset : http://www.image-net.org/

# Training Method
Not used data augmentation technique
Ordinary training with max overfit 50

# Programming Language
Python 3.6
Tensorflow, keras

# OS dependency
windows 10, ubuntu linux

# Result
Resnet - 18's Training result
<div class="imgTopic">
 <h1 class="title"><a href="#">큰 제목</a></h1>
 <p class="content"><a href="#"><img src="https://user-images.githubusercontent.com/29685163/49656613-20093680-fa81-11e8-97fb-ecb63c1ed385.png" alt="" width = "675" height ="350"/><span class="date">2018년12월08일 </span></a></p>
</div>

MobileNet's Training result : 
<img src="https://user-images.githubusercontent.com/29685163/49656474-cdc81580-fa80-11e8-8477-a5b31ab88e8c.png" width = "675" height = "350">


